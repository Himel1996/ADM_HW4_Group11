{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Libraries needed to run the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the libraries needed to run the Notebook\n",
    "\n",
    "from itertools import chain\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Recommendation system** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercise asks to gather the top 10 movies clicked by each user, therefore I implemented a function named \"extract_top_movies_per_user\". This function takes in input the path of the dataset and returns a new dataset with the following details for each user:\n",
    "\n",
    "- *user_id:* The unique identifier of the user\n",
    "- *title:* The title of the movie\n",
    "- *genres:* The genres of the movie\n",
    "- *click_count:* The number of times the user clicked on the movie\n",
    "\n",
    "The function uses pandas to read the dataset, groups the data by user_id, title, and genres, calculates the click count for each movie, and then selects the top 10 movies with the highest click counts for each user. The resulting dataset is sorted by user_id and click_count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_movies_per_user(file_path):\n",
    "    # Reads the DataFrame from the path in input\n",
    "    df = pd.read_csv(file_path).head(10000)\n",
    "\n",
    "    # Grouping by user_id, title, and genres to count the number of clicks for each movie for each user\n",
    "    user_movie_counts = df.groupby(['user_id', 'title', 'genres']).size().reset_index(name='click_count')\n",
    "\n",
    "    # Sorting based on the number of clicks for each user\n",
    "    user_movie_counts.sort_values(by=['user_id', 'click_count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    # Iterates over each user_id and chooses only the top 10 clicked movies\n",
    "    for _, group in user_movie_counts.groupby('user_id'):\n",
    "        result = pd.concat([result, group.head(10)])\n",
    "\n",
    "    # Sorting the result based on user_id and the number of clicks is sorted by user_id and click_count in descending order\n",
    "    result.sort_values(by=['user_id', 'click_count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>click_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005d9a8f4</td>\n",
       "      <td>Joe and Caspar Hit the Road</td>\n",
       "      <td>Documentary, Adventure, Comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001991be8a</td>\n",
       "      <td>Star Trek: First Contact</td>\n",
       "      <td>Action, Adventure, Drama, Sci-Fi, Thriller</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>6 Bullets</td>\n",
       "      <td>Action, Crime, Drama, Thriller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>A Thousand Words</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Adore</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>American Heist</td>\n",
       "      <td>Action, Crime, Drama, Thriller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Anger Management</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Bee Movie</td>\n",
       "      <td>Animation, Adventure, Comedy, Family</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Big Mommas: Like Father, Like Son</td>\n",
       "      <td>Action, Comedy, Crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Damage</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                              title  \\\n",
       "0  0005d9a8f4        Joe and Caspar Hit the Road   \n",
       "1  001991be8a           Star Trek: First Contact   \n",
       "2  0029f6bb1e                          6 Bullets   \n",
       "3  0029f6bb1e                   A Thousand Words   \n",
       "4  0029f6bb1e                              Adore   \n",
       "5  0029f6bb1e                     American Heist   \n",
       "6  0029f6bb1e                   Anger Management   \n",
       "7  0029f6bb1e                          Bee Movie   \n",
       "8  0029f6bb1e  Big Mommas: Like Father, Like Son   \n",
       "9  0029f6bb1e                             Damage   \n",
       "\n",
       "                                       genres  click_count  \n",
       "0              Documentary, Adventure, Comedy            1  \n",
       "1  Action, Adventure, Drama, Sci-Fi, Thriller            2  \n",
       "2              Action, Crime, Drama, Thriller            1  \n",
       "3                               Comedy, Drama            1  \n",
       "4                              Drama, Romance            1  \n",
       "5              Action, Crime, Drama, Thriller            1  \n",
       "6                                      Comedy            1  \n",
       "7        Animation, Adventure, Comedy, Family            1  \n",
       "8                       Action, Comedy, Crime            1  \n",
       "9                               Action, Drama            1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies_per_user = extract_top_movies_per_user('vodclickstream_uk_movies_03.csv')\n",
    "\n",
    "# Printing only the first 10 rows to provide an overview of the dataset\n",
    "top_movies_per_user.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Minhash Signatures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the MinHash signature, we started the process by building a *shingle matrix* for each user. This matrix was built by enumerating all possible genres, assigning unique integers to them, and creating a list for each user. In this list, each position was set to 1 if the genre at that position in the list of all possible genres was present in the user's list of preferred genres; otherwise, the position was set to zero.\n",
    "\n",
    "After building the shingle matrix, we proceeded to calculate the MinHash signature using the minhash_signature function. This function returns a list representing the MinHash signature for the given user based on their preferred genres. The input parameters for this function include:\n",
    "- *user_genres:* List of preferred genres for the user\n",
    "- *num_hashes:* Number of hash functions to use\n",
    "- *genre_dict:* Dictionary mapping genres to unique integers\n",
    "- *num_total_genres:* Total number of unique genres in the dataset\n",
    "\n",
    "To calculate the hash function it was not used any already implemented function, as requested. We chose 100 for the number of hashes since it is generally considered a good amount of hashes for Minhashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash_signature(user_genres, num_hashes, genre_dict, num_total_genres):\n",
    "\n",
    "    # Extracting user genres from the list in input (which contanins 1 string with all the genres) to create the shingle matrix\n",
    "    user_genres = user_genres[0].strip().split(', ')\n",
    "\n",
    "    # Creating the shingle matrix using the genre dictionary and the user genres\n",
    "    shingle_matrix = [0]*num_total_genres\n",
    "    for genre in user_genres:\n",
    "        # Putting 1 only the positions of the preferred genres\n",
    "        shingle_matrix[genre_dict.get(genre)] = 1\n",
    "\n",
    "    # Now let's calculate the MinHash signature, first we initialize the MinHash signature with positive infinity values\n",
    "    minhash_signature = [float('inf')] * num_hashes  \n",
    "    # We Iterate over the rows of the shingle matrix and if the genre is present in the user's preferences we calculate and modify the hash function \n",
    "    for i in range(num_total_genres):\n",
    "        if shingle_matrix[i] == 1:\n",
    "            for j in range(num_hashes):\n",
    "                # Vary the seed to obtain different hash values\n",
    "                hash_value = hash_function(i + j)\n",
    "                \n",
    "                # Update the MinHash signature in position j by taking the minimum hash value\n",
    "                minhash_signature[j] = min(minhash_signature[j], hash_value)\n",
    "\n",
    "    return minhash_signature\n",
    "\n",
    "# Hash function created not using already implemented hash functions, as requested\n",
    "def hash_function(x):\n",
    "    hash_value = 17  # Arbitrary initial value\n",
    "\n",
    "    while x:\n",
    "        digit = x % 10\n",
    "        hash_value = (hash_value * 31) + digit  # Multiplication by an arbitrary prime and addition with the digit\n",
    "        x //= 10  # Removing the last digit\n",
    "\n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that keeps track of each users' preferred genres\n",
    "user_genres_dict = top_movies_per_user.groupby('user_id')['genres'].apply(list).to_dict()\n",
    "\n",
    "# Making a list of all unique genres in the dataset and assigning a unique integer to each genre to build the shingle matrix in the minhash function for each user\n",
    "all_genres = sorted(list(set(chain.from_iterable([genre.split(', ') if isinstance(genre, str) else genre for genre in top_movies_per_user['genres']]))))\n",
    "genre_dict = {genre: i for i, genre in enumerate(all_genres)}\n",
    "num_total_genres = len(all_genres)\n",
    "    \n",
    "# Using the defined function to calculate the MinHash signatures for all users\n",
    "num_hashes = 100\n",
    "minhash_signatures = {user_id: minhash_signature(genres, num_hashes, genre_dict, num_total_genres) for user_id, genres in user_genres_dict.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3 Locality-Sensitive Hashing (LSH)**\n",
    "\n",
    "Now that we have a dictionary containing the signatures for each user, we can utilize the Locality-Sensitive Hashing (LSH) algorithm to identify users with similar interests. In this algorithm, users with similar signatures are grouped into the same bucket. This approach helps in reducing the number of users for which we need to calculate the Jaccard similarity.\n",
    "\n",
    "To find the two users most similar users to the input user, we calculate the Jaccard Similarity for all users in the bucket where the input user is present. We then select the two users with the highest similarity scores. This process is done through the 'find_nearest_neighbors' function, which first executes the LSH algorithm to organize users into buckets based on their MinHash signatures and then calculates the similarity scores to find the **two most similar users**. The function takes the following inputs:\n",
    "- target_user: The user for which we want to find the most similar users\n",
    "- minhash_signatures: The dictionary containing the MinHash signatures for each user\n",
    "- bands: The number of bands used in the LSH algorithm\n",
    "- rows_per_band: The number of rows per band in the LSH algorithm\n",
    "\n",
    "We selected an adequate number of bands and rows to make sure that the similarity measure between users is not too restrictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(minhash_signatures, num_bands, band_size):\n",
    "\n",
    "    # Final resulting dictionary where to put all the other buckets\n",
    "    buckets = {}\n",
    "\n",
    "    for band in range(num_bands):\n",
    "        band_start = band * band_size\n",
    "        band_end = (band + 1) * band_size\n",
    "\n",
    "        # Creating a single bucket where to put the users\n",
    "        band_buckets = {}\n",
    "\n",
    "        # Iterating over users and creating band specific hash buckets\n",
    "        for user_id, signature in minhash_signatures.items():\n",
    "            band_slice = signature[band_start:band_end]\n",
    "            band_hash = hash(tuple(band_slice))\n",
    "\n",
    "            # Checking if the hash bucket already exists, and appending it or creating it accordingly\n",
    "            if band_hash in band_buckets:\n",
    "                band_buckets[band_hash].append(user_id)\n",
    "            else:\n",
    "                band_buckets[band_hash] = [user_id]\n",
    "\n",
    "        # Merging band specific buckets into global buckets\n",
    "        for bucket, users_in_bucket in band_buckets.items():\n",
    "            if bucket in buckets:\n",
    "                buckets[bucket].extend(users_in_bucket)\n",
    "            else:\n",
    "                buckets[bucket] = users_in_bucket\n",
    "\n",
    "    return buckets\n",
    "\n",
    "# Simple function that uses the Jaccard similarity formula to two sets to calculate similarity score\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "\n",
    "    if union > 0:\n",
    "        result = intersection / union\n",
    "    else:\n",
    "        0\n",
    "\n",
    "    return result\n",
    "\n",
    "# Function to find the top 2 most similar users\n",
    "def find_nearest_neighbors(target_user, minhash_signatures, bands, rows_per_band):\n",
    "    \n",
    "    # Apply LSH to divide users in buckets\n",
    "    similar_users = lsh(minhash_signatures, bands, rows_per_band)\n",
    "\n",
    "    # Find the bucket in which the target user is present\n",
    "    target_bucket = None\n",
    "    for _, users_in_bucket in similar_users.items():\n",
    "        if target_user in users_in_bucket:\n",
    "            target_bucket = users_in_bucket\n",
    "            break\n",
    "\n",
    "    if target_bucket is None:\n",
    "        print(f\"User {target_user} not found in buckets.\")\n",
    "        return []\n",
    "\n",
    "    # Calculate exact Jaccard similarity for users in the same bucket\n",
    "    jaccard_similarities = {}\n",
    "    for user_id in target_bucket:\n",
    "        if user_id != target_user:\n",
    "            set1 = set(minhash_signatures[target_user])\n",
    "            set2 = set(minhash_signatures[user_id])\n",
    "            similarity = jaccard_similarity(set1, set2)\n",
    "            jaccard_similarities[user_id] = similarity\n",
    "\n",
    "    # And find the top 2 users with the highest similarity\n",
    "    nearest_neighbors = sorted(jaccard_similarities.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "\n",
    "    # Lastly, extract only the user IDs without similarity scores\n",
    "    nearest_neighbors = [user_id for user_id, _ in nearest_neighbors]\n",
    "\n",
    "    return nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two most similar users to 0823fa7f47 are: ['0449970712', '04f987c36b']\n"
     ]
    }
   ],
   "source": [
    "# Target user is the user which we want to recommend movies to\n",
    "target_user = '0823fa7f47'\n",
    "bands = 6\n",
    "rows_per_band = 10\n",
    "    \n",
    "most_similar_users = find_nearest_neighbors(target_user, minhash_signatures, bands, rows_per_band)\n",
    "\n",
    "print(f\"The two most similar users to {target_user} are: {most_similar_users}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the two most similar neighbors, we can proceed to recommend movies as specified by the exercise, choosing first the movies that these two users have in common, in order based on the number of clicks, and then if there are no more common movies, choosing the most clicked movies by the most similar user first, followed by the other user.\n",
    "We proceeded to recommend movies using the \"recommend_movies\" function, which takes as input:\n",
    "- *most_similar_users:* list containing the two most similar users\n",
    "- *top_movies_per_user:* DataFrame containing information about the top movies per user\n",
    "\n",
    " And returns the list of recommended movies, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(most_similar_users, top_movies_per_user):\n",
    "\n",
    "    common_movies = set()\n",
    "    user_movies_dict = {}\n",
    "    recommended_movies = []\n",
    "\n",
    "    # Finding the clicked movies for each neighbor\n",
    "    for neighbor_id in most_similar_users:\n",
    "        user_movies = set(top_movies_per_user[top_movies_per_user['user_id'] == neighbor_id]['title'])\n",
    "        user_movies_dict[neighbor_id] = user_movies\n",
    "\n",
    "    print(user_movies_dict)\n",
    "\n",
    "    # Finding first the common movies among the neighbors and adding them if present, given the first condition to add movies\n",
    "    common_movies = set.intersection(*user_movies_dict.values())\n",
    "\n",
    "    if common_movies:\n",
    "        common_movies_df = top_movies_per_user[top_movies_per_user['title'].isin(common_movies)]\n",
    "        recommended_movies = common_movies_df.groupby('title')['click_count'].sum().sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "    # If there are no more common movies and the recommended movies are less than 5, recommend the most clicked movies by the most similar neighbor first\n",
    "    if len(recommended_movies) < 5:\n",
    "        \n",
    "        most_similar_neighbor = most_similar_users[0]\n",
    "        most_similar_neighbor_movies = top_movies_per_user[top_movies_per_user['user_id'] == most_similar_neighbor].sort_values(by='click_count', ascending=False)['title'].tolist()\n",
    "        # Deleting movies already present in recommended_movies\n",
    "        most_similar_neighbor_movies = [movie for movie in most_similar_neighbor_movies if movie not in recommended_movies]\n",
    "        remaining_recommendations = most_similar_neighbor_movies[:5 - len(recommended_movies)]\n",
    "        recommended_movies += remaining_recommendations\n",
    "\n",
    "        # If there are still less than 5 recommendations, add movies from the second neighbor based on clicks\n",
    "        if len(recommended_movies) < 5:\n",
    "            second_neighbor = most_similar_users[1]\n",
    "            second_neighbor_movies = top_movies_per_user[top_movies_per_user['user_id'] == second_neighbor].sort_values(by='click_count', ascending=False)['title'].tolist()\n",
    "            # Deleting movies already present in recommended_movies\n",
    "            second_neighbor_movies = [movie for movie in second_neighbor_movies if movie not in recommended_movies]    \n",
    "            remaining_recommendations = second_neighbor_movies[:5 - len(recommended_movies)]\n",
    "            recommended_movies += remaining_recommendations\n",
    "\n",
    "\n",
    "\n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0449970712': {'Skiptrace', 'Some Kind of Hero', 'Winter in Wartime', 'The Water Diviner', 'The Man from the Future', 'Criminal', 'Return to the USS Atlanta: Defender of Guadalcanal', 'World War Z'}, '04f987c36b': {'Criminal'}}\n",
      "Recommended movies for user \"0823fa7f47\":\n",
      "Criminal\n",
      "Return to the USS Atlanta: Defender of Guadalcanal\n",
      "Skiptrace\n",
      "Some Kind of Hero\n",
      "The Man from the Future\n"
     ]
    }
   ],
   "source": [
    "recommended_movies = recommend_movies(most_similar_users, top_movies_per_user)\n",
    "\n",
    "print(f\"Recommended movies for user \\\"{target_user}\\\":\")\n",
    "for movie in recommended_movies:\n",
    "    print(movie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
